{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support, precision_recall_curve\n",
    "from sklearn import ensemble \n",
    "from sklearn import neighbors\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "get_ipython().magic('matplotlib inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3\n",
    "The 2014 KDD Cup asks participants to help DonorsChoose.org identify projects that are exceptionally exciting to the business, at the time of posting. This notebook solves and evaluates the solution to this problem in a variety of ways. Our project goal is to predict at time of posting if the project will be fully funded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Defining constants for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_PRED_VAR = 'fully_funded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HYPERPARAM_TUNING = {\n",
    "    'random_forest': {'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [10, 100, None],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4]},\n",
    "    'svm': {'C': [1.0, 1.5, 2.0],\n",
    "           'kernel': ['linear', 'poly']},\n",
    "    'knn': {'n_neighbors': [2, 5, 7, 9]},\n",
    "    'decision_tree': {'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [10, 100, None],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4]},\n",
    "    'boosting': {'n_estimators': [50, 30, 10],\n",
    "                'learning_rate': [0.5, 1, 1.5]}, \n",
    "    'bagging': {'n_estimators': [5, 10, 15], \n",
    "               'max_samples': [0.2, 0.6, 1.0],\n",
    "               'max_features': [0.2, 0.6, 1.0]}\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKLEARN_BASE_MODELS = {\n",
    "    'logistic_regression': linear_model.LogisticRegressionCV(), \n",
    "    'knn': neighbors.KNeighborsClassifier(),\n",
    "    'decision_tree': tree.DecisionTreeClassifier(), \n",
    "    'random_forest': ensemble.RandomForestClassifier(), \n",
    "    'svm': svm.SVC(), \n",
    "    'boosting': ensemble.AdaBoostClassifier(),\n",
    "    'bagging': ensemble.BaggingClassifier()\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EVALUATION_METHODS = ['accuracy', 'f1', 'roc_auc', 'precision', 'recall'] \n",
    "THRESHOLDS_TO_TEST = [0.01, 0.02, 0.05, 0.10, 0.20, 0.30, 0.50]\n",
    "CLF_TO_CREATE = ['bagging', 'boosting', 'decision_tree', 'random_forest', 'svm', 'logistic_regression', 'knn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTDATE = datetime.datetime.strptime('2011-01-01', '%Y-%m-%d')\n",
    "ENDDATE = datetime.datetime.strptime('2013-12-31', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = read_data('./outcomes.csv')\n",
    "projects = read_data('./projects.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out data that is not in our desired year range (2011 - 2013) using a boolean mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "projects['date_posted'] = pd.to_datetime(projects['date_posted'])\n",
    "mask = (projects['date_posted'] >= STARTDATE) & (projects['date_posted'] <= ENDDATE)\n",
    "projects = projects.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = projects.set_index('projectid').join(\n",
    "    outcomes.set_index('projectid')).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify primary columns and remove extra IDs that won't be predictive and information that won't be available at time of project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df_explor = combined_df[['projectid','school_latitude', 'school_longitude', \n",
    "       'school_city', 'school_state',\n",
    "       'school_zip', 'school_metro', 'school_district', 'school_county',\n",
    "       'school_charter', 'school_magnet', 'school_year_round', 'school_nlns',\n",
    "       'school_kipp', 'school_charter_ready_promise', 'teacher_prefix',\n",
    "       'teacher_teach_for_america', 'teacher_ny_teaching_fellow',\n",
    "       'primary_focus_subject', 'primary_focus_area',\n",
    "       'secondary_focus_subject', 'secondary_focus_area', 'resource_type',\n",
    "       'poverty_level', 'grade_level', 'fulfillment_labor_materials',\n",
    "       'total_price_excluding_optional_support',\n",
    "       'total_price_including_optional_support', 'students_reached',\n",
    "       'eligible_double_your_impact_match', 'eligible_almost_home_match',\n",
    "       'date_posted', 'fully_funded']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Conduct preliminary data analysis\n",
    "- Retain the dataset that was explored for reference\n",
    "- I opted to keep describe rather than histograms, with the option of adding histograms. I had to restart my notebook a bunch, and the histograms took a crazy amount of memory up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outlier_dict = data_summary_stats(df=combined_df_explor, zparam=2, outlier_threshold=1,\n",
    "                                  hist_draw=False, ptitle=\"donors choose correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clean up the dataset\n",
    "- Replace values (t, f) with (1, 0)\n",
    "- Create categorical dummies for any variable with <100 potential options\n",
    "- Fill numerical missing values with the median (typically 0 for boolean)\n",
    "- Fill remaining missing values with 0\n",
    "- Copy the final dataset into a final dataset\n",
    "- For the purposes of this exercise, outliers were retained (none seemed too extreme) and all missing values were imputed similarly (although the functionality to impute specific columns exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace t and f with 1 and 0, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df_filled = combined_df_explor.copy()\n",
    "for col in combined_df_filled.columns:\n",
    "    combined_df_filled[col].replace('f',0, inplace=True)\n",
    "    combined_df_filled[col].replace('t',1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dummies for any categorical with <100 options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in combined_df_filled.columns:\n",
    "    if combined_df_filled[col].dtype == 'object' and len(combined_df_filled[col].unique()) <= 100:\n",
    "        combined_df_filled = make_categorical_dummy(df=combined_df_filled, cat=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute all columns of missing data with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df_filled = fill_values(df=combined_df_filled, fill_missing_method='median')\n",
    "combined_df_filled.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df_final = combined_df_filled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Feature generation\n",
    "To narrow down features:\n",
    "- Ridge regression (cross validated so there is no need for hyper-parameter tuning)\n",
    "- Lasso regression (cross validated so there is no need for hyper-parameter tuning)\n",
    "- Random Forest Classification (default parameters used)\n",
    "- Keep the intersection of features retained in all three sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest features: retained if importance > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_list = rf_features(df=combined_df_final, var_excl=['object', 'datetime64[ns]'], \n",
    "                              y_pred=Y_PRED_VAR, n_jobs=10, random_state=0)\n",
    "\n",
    "rf_feature_names = [x for (x,y) in rf_feature_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso CV features: retained if coeff != 0 \n",
    "- convergence error is an artifact of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcv_feature_list = lcv_features(df=combined_df_final, y_pred=Y_PRED_VAR, \n",
    "                                var_excl=['object', 'datetime64[ns]'], features=None)\n",
    "\n",
    "lcv_feature_names = [x for (x,y) in lcv_feature_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge CV features: retained if coeff != 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rcv_feature_list = rcv_features(df=combined_df_final, y_pred=Y_PRED_VAR, \n",
    "                                var_excl=['object', 'datetime64[ns]'], features=None)\n",
    "\n",
    "rcv_feature_names = [x for (x,y) in rcv_feature_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine intersection of features for the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features_retain = set(rf_feature_names).intersection(lcv_feature_names).intersection(rcv_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_features_retain, end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Hyperparameter tuning\n",
    "- on one test-train split of the data, find the optimal hyperparameters by using a randomized search\n",
    "- although this model is not tested, having a test-train split will enable future functionality of the tuned models (e.g., if I wanted to, I could get testing results as well). \n",
    "- I ran hyperparameter tuning with 5 folds and 2 iterations, largely because my kernel crashed and I wanted to get this in on time :) ideally, I would run it on 5 folds and 30 or more iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get scaled testing and training subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I am not tuning all of the hyperparameters because knn and svm are extremely slow. \n",
    "# I did play with them manually in scratch.  \n",
    "tuning_list = ['random_forest', 'decision_tree', 'boosting', 'bagging']\n",
    "desired_metric = 'roc_auc'\n",
    "final_params = get_hyper_params(df=combined_df_final, feature_list=list(all_features_retain), y_column=Y_PRED_VAR, \n",
    "                                base_models_dict=SKLEARN_BASE_MODELS, random_state=0, \n",
    "                                model_list=tuning_list, scoring_mech=desired_metric, \n",
    "                                hyperparam_tuning_dict=HYPERPARAM_TUNING, cv=5, n_iter=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generating testing and training time series sets and then conducting modeling\n",
    "- note, a time period of 6M was used for convenience (without sacrificing accuracy)\n",
    "- no buffer time zone was used - this data does not have longer term impact that might bleed from testing into training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "series_start = combined_df_final.date_posted.min()\n",
    "series_end = combined_df_final.date_posted.max()\n",
    "\n",
    "time_starts = generate_time_points(series_start=series_start, series_end=series_end, period='6M')\n",
    "time_dfs = wrap_single_split(df=combined_df_final, time_col='date_posted', times=time_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build and evaluate models for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = setup_return_dict(threshold_list=THRESHOLDS_TO_TEST, type_list=EVALUATION_METHODS)\n",
    "\n",
    "rdf, models = cycle_through(time_dfs, clf_list=CLF_TO_CREATE, r=r, param_dict=final_params,\n",
    "                    features=list(all_features_retain), y_column=Y_PRED_VAR, \n",
    "                   threshold_list=THRESHOLDS_TO_TEST, type_list=EVALUATION_METHODS)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
